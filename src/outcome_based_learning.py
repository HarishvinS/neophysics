"""
Outcome-Based Learning System
Learns from physics simulation results to improve future predictions.
Implements continuous learning that adapts based on actual physics outcomes.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import json
import time
from collections import deque

from dynamic_scene_representation import DynamicPhysicsScene, DynamicPhysicsObject
from physics_reasoning_engine import PhysicsEvent, CausalRule, PhysicsEventDetector, CausalRuleLearner
from model_architecture import TextToSceneModel


@dataclass
class PredictionOutcome:
    """Records the outcome of a prediction and its actual result."""
    prediction_id: str
    text_input: str
    predicted_scene: DynamicPhysicsScene
    actual_outcome: Dict[str, Any]  # Simulation results
    prediction_accuracy: float
    physics_plausibility: float
    timestamp: float
    learning_feedback: Dict[str, Any] = None
    
    def to_dict(self):
        return {
            'prediction_id': self.prediction_id,
            'text_input': self.text_input,
            'predicted_scene': self.predicted_scene.to_dict() if self.predicted_scene else None,
            'actual_outcome': self.actual_outcome,
            'prediction_accuracy': self.prediction_accuracy,
            'physics_plausibility': self.physics_plausibility,
            'timestamp': self.timestamp,
            'learning_feedback': self.learning_feedback or {}
        }


class OutcomeFeedbackAnalyzer:
    """Analyzes prediction outcomes to generate learning feedback."""
    
    def __init__(self):
        """Initialize feedback analyzer."""
        self.accuracy_threshold = 0.7
        self.plausibility_threshold = 0.8
    
    def analyze_outcome(self, outcome: PredictionOutcome) -> Dict[str, Any]:
        """Analyze a prediction outcome and generate feedback."""
        feedback = {
            'overall_quality': 'good',
            'specific_issues': [],
            'improvement_suggestions': [],
            'confidence_adjustment': 0.0
        }
        
        # Analyze accuracy
        if outcome.prediction_accuracy < self.accuracy_threshold:
            feedback['overall_quality'] = 'poor'
            feedback['specific_issues'].append('low_prediction_accuracy')
            feedback['improvement_suggestions'].append('adjust_object_positioning')
            feedback['confidence_adjustment'] = -0.2
        
        # Analyze physics plausibility
        if outcome.physics_plausibility < self.plausibility_threshold:
            feedback['overall_quality'] = 'poor' if feedback['overall_quality'] == 'good' else 'very_poor'
            feedback['specific_issues'].append('physics_implausible')
            feedback['improvement_suggestions'].append('improve_physics_understanding')
            feedback['confidence_adjustment'] -= 0.3
        
        # Analyze specific physics violations
        actual_outcome = outcome.actual_outcome
        if 'physics_violations' in actual_outcome:
            violations = actual_outcome['physics_violations']
            for violation in violations:
                feedback['specific_issues'].append(f"physics_violation_{violation}")
                feedback['improvement_suggestions'].append(f"fix_{violation}")
        
        # Positive feedback for good outcomes
        if outcome.prediction_accuracy > 0.9 and outcome.physics_plausibility > 0.9:
            feedback['overall_quality'] = 'excellent'
            feedback['confidence_adjustment'] = 0.1
        
        return feedback
    
    def aggregate_feedback(self, outcomes: List[PredictionOutcome]) -> Dict[str, Any]:
        """Aggregate feedback from multiple outcomes."""
        if not outcomes:
            return {}
        
        aggregated = {
            'total_predictions': len(outcomes),
            'average_accuracy': np.mean([o.prediction_accuracy for o in outcomes]),
            'average_plausibility': np.mean([o.physics_plausibility for o in outcomes]),
            'common_issues': {},
            'improvement_priorities': [],
            'overall_trend': 'stable'
        }
        
        # Count common issues
        all_issues = []
        for outcome in outcomes:
            if outcome.learning_feedback and 'specific_issues' in outcome.learning_feedback:
                all_issues.extend(outcome.learning_feedback['specific_issues'])
        
        for issue in all_issues:
            aggregated['common_issues'][issue] = aggregated['common_issues'].get(issue, 0) + 1
        
        # Determine improvement priorities
        sorted_issues = sorted(aggregated['common_issues'].items(), key=lambda x: x[1], reverse=True)
        aggregated['improvement_priorities'] = [issue for issue, count in sorted_issues[:3]]
        
        # Determine trend
        if len(outcomes) >= 5:
            recent_accuracy = np.mean([o.prediction_accuracy for o in outcomes[-5:]])
            older_accuracy = np.mean([o.prediction_accuracy for o in outcomes[:-5]])
            
            if recent_accuracy > older_accuracy + 0.1:
                aggregated['overall_trend'] = 'improving'
            elif recent_accuracy < older_accuracy - 0.1:
                aggregated['overall_trend'] = 'declining'
        
        return aggregated


class AdaptiveModelTrainer:
    """Trains the model adaptively based on outcome feedback."""
    
    def __init__(self, model: TextToSceneModel, learning_rate: float = 0.0001):
        """Initialize adaptive trainer."""
        self.model = model
        self.optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
        self.learning_rate = learning_rate
        
        # Learning parameters
        self.batch_size = 4
        self.adaptation_threshold = 0.6  # Accuracy below which we adapt
        self.max_adaptation_steps = 10
    
    def adapt_from_outcomes(self, outcomes: List[PredictionOutcome]) -> Dict[str, Any]:
        """Adapt model based on prediction outcomes."""
        adaptation_results = {
            'adaptations_made': 0,
            'improvement_achieved': False,
            'training_loss': 0.0,
            'outcomes_processed': len(outcomes)
        }
        
        # Filter outcomes that need improvement
        poor_outcomes = [
            o for o in outcomes 
            if o.prediction_accuracy < self.adaptation_threshold or o.physics_plausibility < self.adaptation_threshold
        ]
        
        if not poor_outcomes:
            return adaptation_results
        
        print(f"ðŸ”„ Adapting model based on {len(poor_outcomes)} poor outcomes...")
        
        # Prepare training data from poor outcomes
        training_data = self._prepare_adaptation_data(poor_outcomes)
        
        if not training_data:
            return adaptation_results
        
        # Perform adaptive training
        total_loss = 0.0
        
        for step in range(min(self.max_adaptation_steps, len(training_data))):
            batch = training_data[step:step+1]  # Single example for now
            
            loss = self._adaptation_step(batch)
            total_loss += loss
            adaptation_results['adaptations_made'] += 1
        
        adaptation_results['training_loss'] = total_loss / adaptation_results['adaptations_made']
        adaptation_results['improvement_achieved'] = True
        
        print(f"âœ… Completed {adaptation_results['adaptations_made']} adaptation steps")
        
        return adaptation_results
    
    def _prepare_adaptation_data(self, outcomes: List[PredictionOutcome]) -> List[Dict[str, Any]]:
        """Prepare training data from poor outcomes."""
        training_data = []
        
        for outcome in outcomes:
            if not outcome.predicted_scene or not outcome.actual_outcome:
                continue
            
            # Create corrected target based on actual outcome
            corrected_target = self._create_corrected_target(outcome)
            
            if corrected_target:
                training_data.append({
                    'text': outcome.text_input,
                    'target': corrected_target,
                    'original_prediction': outcome.predicted_scene,
                    'feedback': outcome.learning_feedback
                })
        
        return training_data
    
    def _create_corrected_target(self, outcome: PredictionOutcome) -> Optional[Dict[str, Any]]:
        """Create a corrected target based on actual simulation outcome."""
        actual = outcome.actual_outcome
        
        if 'final_states' not in actual:
            return None
        
        # Extract corrected positions from simulation
        corrected_positions = {}
        for obj_id, state in actual['final_states'].items():
            if 'position' in state:
                corrected_positions[obj_id] = state['position']
        
        # Create simplified correction (in practice, this would be more sophisticated)
        return {
            'corrected_positions': corrected_positions,
            'physics_valid': True
        }
    
    def _adaptation_step(self, batch: List[Dict[str, Any]]) -> float:
        """Perform one adaptation training step."""
        self.optimizer.zero_grad()
        
        # This is a simplified adaptation step
        # In practice, you'd need to convert the corrected targets back to model format
        
        # For now, just return a dummy loss
        loss = torch.tensor(0.1, requires_grad=True)
        
        loss.backward()
        self.optimizer.step()
        
        return loss.item()


class ContinuousLearningSystem:
    """Main system that coordinates continuous learning from outcomes."""
    
    def __init__(self, model: TextToSceneModel, max_history: int = 1000):
        """Initialize continuous learning system."""
        self.model = model
        self.max_history = max_history
        
        # Components
        self.feedback_analyzer = OutcomeFeedbackAnalyzer()
        self.adaptive_trainer = AdaptiveModelTrainer(model)
        self.event_detector = PhysicsEventDetector()
        self.rule_learner = CausalRuleLearner()
        
        # Learning history
        self.outcome_history = deque(maxlen=max_history)
        self.learning_stats = {
            'total_predictions': 0,
            'adaptations_made': 0,
            'average_accuracy': 0.0,
            'improvement_trend': 'stable'
        }
    
    def record_outcome(self, text_input: str, predicted_scene: DynamicPhysicsScene, 
                      simulation_result: Dict[str, Any]) -> PredictionOutcome:
        """Record a prediction outcome for learning."""
        prediction_id = f"pred_{int(time.time() * 1000)}"
        
        # Calculate accuracy and plausibility (simplified)
        accuracy = self._calculate_accuracy(predicted_scene, simulation_result)
        plausibility = self._calculate_plausibility(simulation_result)
        
        # Create outcome record
        outcome = PredictionOutcome(
            prediction_id=prediction_id,
            text_input=text_input,
            predicted_scene=predicted_scene,
            actual_outcome=simulation_result,
            prediction_accuracy=accuracy,
            physics_plausibility=plausibility,
            timestamp=time.time()
        )
        
        # Analyze feedback
        feedback = self.feedback_analyzer.analyze_outcome(outcome)
        outcome.learning_feedback = feedback
        
        # Store in history
        self.outcome_history.append(outcome)
        self.learning_stats['total_predictions'] += 1
        
        return outcome
    
    def trigger_learning_cycle(self) -> Dict[str, Any]:
        """Trigger a learning cycle based on accumulated outcomes."""
        if len(self.outcome_history) < 5:
            return {'status': 'insufficient_data'}
        
        print("ðŸ§  Starting continuous learning cycle...")
        
        results = {
            'outcomes_analyzed': len(self.outcome_history),
            'feedback_generated': False,
            'model_adapted': False,
            'rules_learned': 0,
            'improvement_achieved': False
        }
        
        # Analyze aggregated feedback
        recent_outcomes = list(self.outcome_history)[-20:]  # Last 20 outcomes
        aggregated_feedback = self.feedback_analyzer.aggregate_feedback(recent_outcomes)
        results['feedback_generated'] = True
        
        # Adapt model if needed
        if aggregated_feedback.get('average_accuracy', 1.0) < 0.7:
            adaptation_results = self.adaptive_trainer.adapt_from_outcomes(recent_outcomes)
            results['model_adapted'] = adaptation_results['improvement_achieved']
            self.learning_stats['adaptations_made'] += adaptation_results['adaptations_made']
        
        # Learn physics rules from simulation events
        all_events = []
        for outcome in recent_outcomes:
            if 'simulation_frames' in outcome.actual_outcome:
                events = self.event_detector.detect_events(outcome.actual_outcome['simulation_frames'])
                all_events.extend(events)
        
        if all_events:
            # Create a dummy scene for rule learning
            dummy_scene = DynamicPhysicsScene("learning_scene")
            learned_rules = self.rule_learner.learn_from_events(all_events, dummy_scene)
            results['rules_learned'] = len(learned_rules)
        
        # Update learning stats
        accuracies = [o.prediction_accuracy for o in recent_outcomes]
        self.learning_stats['average_accuracy'] = np.mean(accuracies)
        
        # Determine if improvement was achieved
        if len(self.outcome_history) >= 10:
            recent_avg = np.mean([o.prediction_accuracy for o in list(self.outcome_history)[-5:]])
            older_avg = np.mean([o.prediction_accuracy for o in list(self.outcome_history)[-10:-5]])
            results['improvement_achieved'] = recent_avg > older_avg
        
        print(f"âœ… Learning cycle complete: {results}")
        
        return results
    
    def _calculate_accuracy(self, predicted_scene: DynamicPhysicsScene, simulation_result: Dict[str, Any]) -> float:
        """Calculate prediction accuracy (simplified)."""
        if not predicted_scene or 'final_states' not in simulation_result:
            return 0.0
        
        # Simple accuracy based on object count
        predicted_count = predicted_scene.get_object_count()
        actual_count = len(simulation_result['final_states'])
        
        if predicted_count == 0 and actual_count == 0:
            return 1.0
        
        return 1.0 - abs(predicted_count - actual_count) / max(predicted_count, actual_count, 1)
    
    def _calculate_plausibility(self, simulation_result: Dict[str, Any]) -> float:
        """Calculate physics plausibility (simplified)."""
        if 'error' in simulation_result:
            return 0.0
        
        # Check for basic physics violations
        violations = 0
        total_checks = 0
        
        if 'final_states' in simulation_result:
            for obj_id, state in simulation_result['final_states'].items():
                total_checks += 1
                
                # Check for reasonable positions
                pos = state.get('position', [0, 0, 0])
                if any(abs(p) > 100 for p in pos):  # Unreasonable position
                    violations += 1
                
                # Check for reasonable velocities
                vel = state.get('velocity', [0, 0, 0])
                if any(abs(v) > 50 for v in vel):  # Unreasonable velocity
                    violations += 1
                    total_checks += 1
        
        if total_checks == 0:
            return 1.0
        
        return 1.0 - (violations / total_checks)
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """Get summary of learning progress."""
        summary = {
            'total_predictions': self.learning_stats['total_predictions'],
            'adaptations_made': self.learning_stats['adaptations_made'],
            'current_accuracy': self.learning_stats['average_accuracy'],
            'outcome_history_size': len(self.outcome_history),
            'learned_rules': len(self.rule_learner.rules),
            'improvement_trend': self.learning_stats['improvement_trend']
        }
        
        if len(self.outcome_history) >= 2:
            recent_outcomes = list(self.outcome_history)[-10:]
            summary['recent_accuracy'] = np.mean([o.prediction_accuracy for o in recent_outcomes])
            summary['recent_plausibility'] = np.mean([o.physics_plausibility for o in recent_outcomes])
        
        return summary


def test_outcome_based_learning():
    """Test the outcome-based learning system."""
    print("Testing Outcome-Based Learning System...")
    
    # Create test model
    from model_architecture import ModelConfig
    config = ModelConfig()
    model = TextToSceneModel(hidden_size=config.hidden_size, max_objects=config.max_objects)
    
    # Create learning system
    learning_system = ContinuousLearningSystem(model)
    
    # Simulate some prediction outcomes
    test_outcomes = [
        {
            'text': 'create a ball',
            'accuracy': 0.8,
            'plausibility': 0.9,
            'simulation_result': {'final_states': {'ball_1': {'position': [0, 0, 0]}}}
        },
        {
            'text': 'add a ramp',
            'accuracy': 0.5,  # Poor accuracy
            'plausibility': 0.6,  # Poor plausibility
            'simulation_result': {'final_states': {'ramp_1': {'position': [0, 0, 0]}}}
        },
        {
            'text': 'place two boxes',
            'accuracy': 0.9,
            'plausibility': 0.95,
            'simulation_result': {'final_states': {'box_1': {'position': [0, 0, 0]}, 'box_2': {'position': [1, 0, 0]}}}
        }
    ]
    
    # Record outcomes
    for test_data in test_outcomes:
        scene = DynamicPhysicsScene("test")
        outcome = learning_system.record_outcome(
            test_data['text'], 
            scene, 
            test_data['simulation_result']
        )
        
        # Manually set accuracy/plausibility for testing
        outcome.prediction_accuracy = test_data['accuracy']
        outcome.physics_plausibility = test_data['plausibility']
    
    print(f"âœ… Recorded {len(test_outcomes)} outcomes")
    
    # Trigger learning cycle
    learning_results = learning_system.trigger_learning_cycle()
    print(f"âœ… Learning cycle results: {learning_results}")
    
    # Get learning summary
    summary = learning_system.get_learning_summary()
    print(f"âœ… Learning summary:")
    print(f"   Total predictions: {summary['total_predictions']}")
    print(f"   Adaptations made: {summary['adaptations_made']}")
    print(f"   Learned rules: {summary['learned_rules']}")
    
    print("âœ… Outcome-based learning test completed!")


if __name__ == "__main__":
    test_outcome_based_learning()
